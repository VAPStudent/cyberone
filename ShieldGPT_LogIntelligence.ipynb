{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yy1NMQGwRiur"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit faker\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nou4cfkxRp7U"
      },
      "outputs": [],
      "source": [
        "#create synthetic data\n",
        "import random\n",
        "from faker import Faker\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "def generate_synthetic_logs(num_logs):\n",
        "    users = ['rbinnajim.c', 'nmzuabi', 'mhassanien.c', 'sadmin']\n",
        "    logs = []\n",
        "\n",
        "    for _ in range(num_logs):\n",
        "        user = random.choice(users)\n",
        "        ip = fake.ipv4()\n",
        "        session_id = fake.uuid4()\n",
        "        timestamp = fake.date_time_this_month()\n",
        "\n",
        "        # Log for LDAP Authentication\n",
        "        log = f\"{timestamp} LDAP Authentication SUCCESS for User[{user}]. Client IP[{ip}]\\n\"\n",
        "\n",
        "        # OTP bypass for specific users like 'sadmin', otherwise OTP success\n",
        "        if user != 'sadmin':\n",
        "            log += f\"{timestamp} OTP Authentication SUCCESS for User[{user}]. Client IP[{ip}]\\n\"\n",
        "\n",
        "        log += f\"{timestamp} Session ID[{session_id}], Authentication Done. Redirecting to Siebel\\n\"\n",
        "        logs.append(log)\n",
        "\n",
        "    return '\\n'.join(logs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KsDuhAnRyji"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import re\n",
        "\n",
        "# Step 1: Generate synthetic logs and allow download\n",
        "@st.cache_data\n",
        "def generate_synthetic_logs(num_logs):\n",
        "    from faker import Faker\n",
        "    fake = Faker()\n",
        "\n",
        "    users = ['rbinnajim.c', 'nmzuabi', 'mhassanien.c', 'sadmin']\n",
        "    logs = []\n",
        "\n",
        "    for _ in range(num_logs):\n",
        "        user = random.choice(users)\n",
        "        ip = fake.ipv4()\n",
        "        session_id = fake.uuid4()\n",
        "        timestamp = fake.date_time_this_month()\n",
        "\n",
        "        # Log for LDAP Authentication\n",
        "        log = f\"{timestamp} LDAP Authentication SUCCESS for User[{user}]. Client IP[{ip}]\\n\"\n",
        "\n",
        "        # OTP bypass for specific users like 'sadmin', otherwise OTP success\n",
        "        if user != 'sadmin':\n",
        "            log += f\"{timestamp} OTP Authentication SUCCESS for User[{user}]. Client IP[{ip}]\\n\"\n",
        "\n",
        "        log += f\"{timestamp} Session ID[{session_id}], Authentication Done. Redirecting to Siebel\\n\"\n",
        "        logs.append(log)\n",
        "\n",
        "    return '\\n'.join(logs)\n",
        "\n",
        "# Step 2: Parse uploaded log data\n",
        "def parse_logs(log_data):\n",
        "    # Define patterns to match LDAP, OTP successes, and bypass attempts\n",
        "    pattern = r\"LDAP Authentication SUCCESS for User\\[(.*?)\\]\\. Client IP\\[(.*?)\\]\"\n",
        "    ldap_matches = re.findall(pattern, log_data)\n",
        "\n",
        "    otp_pattern = r\"OTP Authentication SUCCESS for User\\[(.*?)\\]\\. Client IP\\[(.*?)\\]\"\n",
        "    otp_matches = re.findall(otp_pattern, log_data)\n",
        "\n",
        "    bypass_pattern = r\"LDAP Authentication SUCCESS for User\\[(.*?)\\] .*? Redirecting to Siebel\"\n",
        "    bypass_matches = re.findall(bypass_pattern, log_data)\n",
        "\n",
        "    return ldap_matches, otp_matches, bypass_matches\n",
        "\n",
        "# Step 3: Streamlit app logic\n",
        "def main():\n",
        "    st.title(\"Login Log Analysis Tool\")\n",
        "\n",
        "    # Generate synthetic logs and allow user to download them\n",
        "    st.sidebar.header(\"Generate Synthetic Logs\")\n",
        "    num_logs = st.sidebar.slider(\"Number of Logs\", 1, 100, 10)\n",
        "\n",
        "    if st.sidebar.button(\"Generate Logs\"):\n",
        "        synthetic_logs = generate_synthetic_logs(num_logs)\n",
        "        st.sidebar.download_button(\n",
        "            label=\"Download Synthetic Logs\",\n",
        "            data=synthetic_logs,\n",
        "            file_name=\"synthetic_logs.txt\"\n",
        "        )\n",
        "\n",
        "    # Upload log file section\n",
        "    st.header(\"Upload Log File\")\n",
        "    uploaded_file = st.file_uploader(\"Choose a log file\", type=[\"txt\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Read the log data\n",
        "        log_data = uploaded_file.read().decode(\"utf-8\")\n",
        "\n",
        "        # Display raw logs\n",
        "        st.subheader(\"Uploaded Log Data\")\n",
        "        st.text_area(\"Logs\", log_data, height=300)\n",
        "\n",
        "        # Parse the logs\n",
        "        ldap_matches, otp_matches, bypass_matches = parse_logs(log_data)\n",
        "\n",
        "        # Display findings\n",
        "        st.subheader(\"Analysis of Logs\")\n",
        "\n",
        "        st.write(\"### LDAP Authentication Successes\")\n",
        "        if ldap_matches:\n",
        "            for user, ip in ldap_matches:\n",
        "                st.write(f\"User: {user}, IP: {ip}\")\n",
        "        else:\n",
        "            st.write(\"No LDAP Authentication Successes found.\")\n",
        "\n",
        "        st.write(\"### OTP Authentication Successes\")\n",
        "        if otp_matches:\n",
        "            for user, ip in otp_matches:\n",
        "                st.write(f\"User: {user}, IP: {ip}\")\n",
        "        else:\n",
        "            st.write(\"No OTP Authentication Successes found.\")\n",
        "\n",
        "        st.write(\"### Bypass Attempts (No OTP)\")\n",
        "        if bypass_matches:\n",
        "            for user, ip in bypass_matches:\n",
        "                st.write(f\"User: {user}, IP: {ip} (OTP Bypass)\")\n",
        "        else:\n",
        "            st.write(\"No OTP Bypass Attempts found.\")\n",
        "\n",
        "# Run the app\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fH1SWrNcN2yg"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit faker pandas numpy matplotlib plotly scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BttVraKWaX4I"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit pandas matplotlib seaborn numpy python-docx openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Working app code as on 5th Nov 2024\n",
        "import random\n",
        "from faker import Faker\n",
        "import streamlit as st\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Step 1: Generate synthetic logs\n",
        "def generate_synthetic_logs(num_logs):\n",
        "    fake = Faker()\n",
        "    users = ['rbinnajim.c', 'nmzuabi', 'mhassanien.c', 'sadmin']\n",
        "    logs = []\n",
        "    now = datetime.now()\n",
        "\n",
        "    for _ in range(num_logs):\n",
        "        timestamp = now - timedelta(minutes=random.randint(1, 10000))\n",
        "        user = random.choice(users)\n",
        "        ip = fake.ipv4()\n",
        "        session_id = fake.uuid4()\n",
        "\n",
        "        # Log for LDAP Authentication\n",
        "        log = f\"{timestamp} LDAP Authentication SUCCESS for User[{user}]. Client IP[{ip}]\\n\"\n",
        "\n",
        "        if user != 'sadmin':\n",
        "            log += f\"{timestamp} OTP Authentication SUCCESS for User[{user}]. Client IP[{ip}]\\n\"\n",
        "\n",
        "        log += f\"{timestamp} Session ID[{session_id}], Authentication Done. Redirecting to Siebel\\n\"\n",
        "        logs.append(log)\n",
        "\n",
        "    return '\\n'.join(logs)\n",
        "\n",
        "# Step 2: Parse logs\n",
        "def parse_logs(log_data):\n",
        "    ldap_pattern = r\"(\\d+-\\d+-\\d+ \\d+:\\d+:\\d+).*?LDAP Authentication SUCCESS for User\\[(.*?)\\]\"\n",
        "    otp_pattern = r\"(\\d+-\\d+-\\d+ \\d+:\\d+:\\d+).*?OTP Authentication SUCCESS for User\\[(.*?)\\]\"\n",
        "\n",
        "    ldap_matches = re.findall(ldap_pattern, log_data)\n",
        "    otp_matches = re.findall(otp_pattern, log_data)\n",
        "\n",
        "    ldap_df = pd.DataFrame(ldap_matches, columns=['timestamp', 'user'])\n",
        "    ldap_df['timestamp'] = pd.to_datetime(ldap_df['timestamp'])\n",
        "    otp_df = pd.DataFrame(otp_matches, columns=['timestamp', 'user'])\n",
        "    otp_df['timestamp'] = pd.to_datetime(otp_df['timestamp'])\n",
        "\n",
        "    return ldap_df, otp_df\n",
        "\n",
        "# Step 3: Visualize log data\n",
        "def visualize_data(ldap_df, otp_df):\n",
        "    st.subheader(\"Login Trends Over Time\")\n",
        "    st.write(\"This graph shows the trend of LDAP authentication success events over time, helping to observe if login activities have increased or decreased.\")\n",
        "\n",
        "    # Plot LDAP Authentication Trend\n",
        "    ldap_df['date'] = ldap_df['timestamp'].dt.date\n",
        "    ldap_counts = ldap_df.groupby('date').size()\n",
        "\n",
        "    fig = px.line(ldap_counts, title=\"LDAP Authentication Success Trend\")\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    # Plot OTP Authentication Trend\n",
        "    otp_df['date'] = otp_df['timestamp'].dt.date\n",
        "    otp_counts = otp_df.groupby('date').size()\n",
        "\n",
        "    st.write(\"This graph shows the trend of OTP authentication success events, which helps in analyzing the additional security verification activities.\")\n",
        "    fig = px.line(otp_counts, title=\"OTP Authentication Success Trend\", color_discrete_sequence=['green'])\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    # Identify and plot anomalies\n",
        "    st.subheader(\"Anomalies Detection\")\n",
        "    st.write(\"The bar chart below shows the hourly counts of LDAP authentication events. Bars in red highlight any anomalies where login activity significantly exceeds the norm.\")\n",
        "\n",
        "    ldap_df['hour'] = ldap_df['timestamp'].dt.hour\n",
        "    hourly_counts = ldap_df.groupby('hour').size()\n",
        "\n",
        "    threshold = hourly_counts.mean() + 2 * hourly_counts.std()  # basic anomaly threshold\n",
        "    anomalies = hourly_counts[hourly_counts > threshold]\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    hourly_counts.plot(ax=ax, color=\"blue\", label=\"Hourly Counts\")\n",
        "    anomalies.plot(ax=ax, kind=\"bar\", color=\"red\", label=\"Anomalies\")\n",
        "    plt.axhline(y=threshold, color='orange', linestyle='--', label='Threshold')\n",
        "    plt.legend()\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    # Prediction of LDAP authentication trend\n",
        "    st.subheader(\"Trend Prediction\")\n",
        "    st.write(\"This graph provides a forecast for LDAP authentication events based on past data trends, giving insight into expected future login activities.\")\n",
        "\n",
        "    ldap_counts.index = pd.to_datetime(ldap_counts.index)\n",
        "    ldap_counts = ldap_counts.reset_index()\n",
        "    ldap_counts['date_ordinal'] = ldap_counts['date'].apply(lambda x: x.toordinal())\n",
        "\n",
        "    X = np.array(ldap_counts['date_ordinal']).reshape(-1, 1)\n",
        "    y = np.array(ldap_counts[0])\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X, y)\n",
        "    ldap_counts['predicted'] = model.predict(X)\n",
        "\n",
        "    fig = px.line(ldap_counts, x='date', y='predicted', title=\"Predicted LDAP Authentication Trend\")\n",
        "    fig.add_scatter(x=ldap_counts['date'], y=ldap_counts[0], mode='lines', name='Actual')\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    mse = mean_squared_error(y, ldap_counts['predicted'])\n",
        "    st.write(f\"Prediction Mean Squared Error: {mse:.2f}\")\n",
        "\n",
        "# Step 4: Q&A Interface\n",
        "def handle_question(question, ldap_df, otp_df):\n",
        "    question = question.lower()\n",
        "\n",
        "    if \"trend in logins\" in question:\n",
        "        response = \"The trend shows the daily count of successful LDAP and OTP logins. Generally, an increase indicates more usage or activity, while a decrease could suggest fewer access attempts.\"\n",
        "    elif \"anomalies\" in question:\n",
        "        response = \"Anomalies are detected where hourly login counts exceed a threshold based on average activity. These may indicate unusual access attempts or periods of high demand.\"\n",
        "    elif \"prediction\" in question:\n",
        "        response = \"The prediction graph forecasts future LDAP login events using a linear model, helping to anticipate future login patterns.\"\n",
        "    else:\n",
        "        response = \"Sorry, I didn't understand the question. Try asking about 'trend in logins,' 'anomalies,' or 'prediction'.\"\n",
        "\n",
        "    return response\n",
        "\n",
        "# Step 5: Streamlit App\n",
        "def main():\n",
        "    st.title(\"Enhanced Login Log Analysis Tool with Q&A Interface\")\n",
        "\n",
        "    # Generate synthetic logs\n",
        "    st.sidebar.header(\"Generate Synthetic Logs\")\n",
        "    num_logs = st.sidebar.slider(\"Number of Logs\", 1, 1000, 100)\n",
        "\n",
        "    if st.sidebar.button(\"Generate Logs\"):\n",
        "        synthetic_logs = generate_synthetic_logs(num_logs)\n",
        "        st.sidebar.download_button(\n",
        "            label=\"Download Synthetic Logs\",\n",
        "            data=synthetic_logs,\n",
        "            file_name=\"synthetic_logs.txt\"\n",
        "        )\n",
        "\n",
        "    # Upload log file section\n",
        "    st.header(\"Upload Log File\")\n",
        "    uploaded_file = st.file_uploader(\"Choose a log file\", type=[\"txt\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        log_data = uploaded_file.read().decode(\"utf-8\")\n",
        "        ldap_df, otp_df = parse_logs(log_data)\n",
        "\n",
        "        st.subheader(\"Raw Log Data\")\n",
        "        st.text_area(\"Logs\", log_data, height=200)\n",
        "\n",
        "        # Display parsed data tables\n",
        "        st.subheader(\"Parsed LDAP Log Data\")\n",
        "        st.dataframe(ldap_df)\n",
        "\n",
        "        st.subheader(\"Parsed OTP Log Data\")\n",
        "        st.dataframe(otp_df)\n",
        "\n",
        "        # Visualize data with trends, anomalies, and predictions\n",
        "        visualize_data(ldap_df, otp_df)\n",
        "\n",
        "        # Q&A Interface\n",
        "        st.subheader(\"Ask Questions About the Log Data\")\n",
        "        user_question = st.text_input(\"Enter your question about the log data:\")\n",
        "\n",
        "        if user_question:\n",
        "            response = handle_question(user_question, ldap_df, otp_df)\n",
        "            st.write(response)\n",
        "\n",
        "# Run the app\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "PezpdO7TONnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvbuG5xZMfZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b34323c1-34d3-42f1-cc0f-98570ed233e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\n",
            "added 22 packages in 6s\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLFz8EGsMje0",
        "outputId": "c63f77a1-6dc8-44a3-85c4-ded18dbb79c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.221.196.118\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://bright-frogs-shine.loca.lt\n",
            "/content/node_modules/localtunnel/bin/lt.js:81\n",
            "    throw err;\n",
            "    ^\n",
            "\n",
            "Error: connection refused: localtunnel.me:10103 (check your firewall settings)\n",
            "    at Socket.<anonymous> \u001b[90m(/content/\u001b[39mnode_modules/\u001b[4mlocaltunnel\u001b[24m/lib/TunnelCluster.js:52:11\u001b[90m)\u001b[39m\n",
            "\u001b[90m    at Socket.emit (node:events:517:28)\u001b[39m\n",
            "\u001b[90m    at emitErrorNT (node:internal/streams/destroy:151:8)\u001b[39m\n",
            "\u001b[90m    at emitErrorCloseNT (node:internal/streams/destroy:116:3)\u001b[39m\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)\u001b[39m\n",
            "\n",
            "Node.js v18.20.5\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py &> /content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}